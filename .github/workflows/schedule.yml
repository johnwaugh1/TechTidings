name: Run Scraper Every 3 Hours

on:
  schedule:
    - cron: "0 */3 * * *"  # This sets the cron schedule to every 3 hours
  workflow_dispatch: # This allows you to trigger the action manually from GitHub UI if needed

jobs:
  run-scraper:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.x'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r server/scraper/requirements.txt  # Install the necessary Python packages

      - name: Run Scraper and Filter
        run: |
          python server/scraper/scraper.py    # Run your scraper.py
          python server/scraper/filter.py     # Run your filter.py
        working-directory: server/scraper

      - name: Trigger Netlify Function (optional)
        run: |
          curl -X POST https://api.netlify.com/sites/YOUR_NETLIFY_SITE_NAME/functions/runScraper
        env:
          NETLIFY_API_TOKEN: ${{ secrets.NETLIFY_API_TOKEN }}
